{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1Ô∏è‚É£ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain faiss-cpu sentence-transformers google-generativeai langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2Ô∏è‚É£ Data Ingestion from a Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Load text data from a file\n",
    "data_loader = TextLoader(\"data.txt\")\n",
    "documents = data_loader.load()\n",
    "print(\"--------documents---------\",documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3Ô∏è‚É£ Data Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data.txt'}, page_content='Natural Language Processing (NLP) is a subfield of Artificial Intelligence that focuses on the interaction between computers and human language. It enables machines to understand, interpret, and generate human language in a way that is both meaningful and useful.\\n\\nKey components of NLP include tokenization, part-of-speech tagging, named entity recognition, sentiment analysis, and syntactic parsing. These techniques allow NLP models to process large volumes of text efficiently.'),\n",
       " Document(metadata={'source': 'data.txt'}, page_content='One of the most widely used applications of NLP is machine translation, where algorithms like Google Translate convert text from one language to another. Another key application is text summarization, which helps extract key information from lengthy documents.'),\n",
       " Document(metadata={'source': 'data.txt'}, page_content='Recent advancements in NLP have been driven by deep learning models such as transformers, including BERT, GPT, and Gemini. These models leverage large-scale datasets and self-attention mechanisms to improve accuracy and contextual understanding.'),\n",
       " Document(metadata={'source': 'data.txt'}, page_content='Retrieval-Augmented Generation (RAG) has emerged as a powerful approach in NLP, enhancing generative models by incorporating relevant external knowledge. By retrieving information from vector databases before generating text, RAG significantly improves response relevance and factual correctness.'),\n",
       " Document(metadata={'source': 'data.txt'}, page_content='NLP continues to evolve, with applications spanning chatbots, voice assistants, content moderation, and more. With the integration of multimodal AI, future NLP models will become even more sophisticated in understanding and generating human-like text.')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Define a chunking strategy\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=50\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4Ô∏è‚É£ Store Embeddings in Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/codespace/.python/current/lib/python3.12/site-packages (0.3.20)\n",
      "Requirement already satisfied: langchain-google-genai in /home/codespace/.python/current/lib/python3.12/site-packages (2.0.10)\n",
      "Collecting langchain-google-genai\n",
      "  Using cached langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: google-generativeai in /home/codespace/.python/current/lib/python3.12/site-packages (0.8.4)\n",
      "Requirement already satisfied: faiss-cpu in /home/codespace/.python/current/lib/python3.12/site-packages (1.10.0)\n",
      "Requirement already satisfied: sentence-transformers in /home/codespace/.python/current/lib/python3.12/site-packages (3.4.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain) (0.3.43)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain) (0.3.13)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/codespace/.local/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai)\n",
      "  Using cached google_ai_generativelanguage-0.6.16-py3-none-any.whl.metadata (5.7 kB)\n",
      "INFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "  Using cached google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Using cached google_generativeai-0.8.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Using cached google_generativeai-0.8.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "INFO: pip is still looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached google_generativeai-0.8.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Using cached google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached google_generativeai-0.7.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Using cached google_generativeai-0.7.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Using cached google_generativeai-0.6.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Using cached google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Using cached google_generativeai-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Using cached google_generativeai-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Using cached google_generativeai-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Using cached google_generativeai-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Using cached google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached google_generativeai-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Using cached google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached google_generativeai-0.3.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached google_generativeai-0.3.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Using cached google_generativeai-0.2.2-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Using cached google_generativeai-0.2.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Using cached google_generativeai-0.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Using cached google_generativeai-0.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /home/codespace/.python/current/lib/python3.12/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /home/codespace/.python/current/lib/python3.12/site-packages (from google-generativeai) (2.24.1)\n",
      "Requirement already satisfied: google-api-python-client in /home/codespace/.python/current/lib/python3.12/site-packages (from google-generativeai) (2.163.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in /home/codespace/.python/current/lib/python3.12/site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: tqdm in /home/codespace/.python/current/lib/python3.12/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /home/codespace/.local/lib/python3.12/site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /home/codespace/.local/lib/python3.12/site-packages (from faiss-cpu) (2.2.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from sentence-transformers) (4.49.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (2.5.1+cpu)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (1.6.0)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from sentence-transformers) (0.29.2)\n",
      "Requirement already satisfied: Pillow in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from google-api-core->google-generativeai) (1.69.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/codespace/.python/current/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/codespace/.python/current/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/codespace/.python/current/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/codespace/.local/lib/python3.12/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/codespace/.python/current/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "FAISS index and documents stored successfully.\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade langchain langchain-google-genai google-generativeai faiss-cpu sentence-transformers\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import google.generativeai as genai\n",
    "import pickle\n",
    "\n",
    "# ‚úÖ Use HuggingFaceEmbeddings instead of raw SentenceTransformer\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Sample documents (Replace this with actual data)\n",
    "# documents = [\n",
    "#     {\"text\": \"Natural Language Processing (NLP) enables computers to understand human language.\"},\n",
    "#     {\"text\": \"Sentence Transformers generate vector embeddings for text similarity tasks.\"},\n",
    "#     {\"text\": \"FAISS (Facebook AI Similarity Search) efficiently searches large vector spaces.\"}\n",
    "# ]\n",
    "\n",
    "# ‚úÖ Convert documents to LangChain format\n",
    "from langchain.schema import Document\n",
    "# chunks = [Document(page_content=doc[\"text\"]) for doc in documents]\n",
    "\n",
    "# ‚úÖ Create FAISS vector store\n",
    "vector_store = FAISS.from_documents(chunks, embedding_model)\n",
    "\n",
    "# ‚úÖ Save FAISS index and documents separately\n",
    "vector_store.save_local(\"faiss_index\")\n",
    "with open(\"faiss_docs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(documents, f)\n",
    "\n",
    "print(\"FAISS index and documents stored successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5Ô∏è‚É£ Query Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ **Q:** What is NLP?\n",
      "üîπ **A:** Based on the provided text, Natural Language Processing (NLP) is a subfield of Artificial Intelligence that focuses on the interaction between computers and human language.  It enables machines to understand, interpret, and generate human language in a meaningful and useful way.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚úÖ Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "# ‚úÖ Load FAISS index\n",
    "# vector_store = FAISS.load_local(\"faiss_index\", embedding_model)\n",
    "# ‚úÖ Load FAISS index with safe deserialization\n",
    "vector_store = FAISS.load_local(\"faiss_index\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "\n",
    "# ‚úÖ Initialize retriever\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# ‚úÖ Configure Gemini API\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "# ‚úÖ Load Google Gemini LLM\n",
    "def query_gemini(query, context):\n",
    "    \"\"\"Uses Gemini Pro to answer questions based on retrieved context.\"\"\"\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    prompt = f\"Answer the following question based on the provided context:\\n\\nContext: {context}\\n\\nQuestion: {query}\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# ‚úÖ Perform Retrieval & Answer Generation\n",
    "query = \"What is NLP?\"\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "# ‚úÖ Generate response using Gemini\n",
    "response = query_gemini(query, context)\n",
    "print(f\"\\nüîπ **Q:** {query}\\nüîπ **A:** {response}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
